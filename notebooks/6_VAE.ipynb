{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import datetime as dt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "tri_path = os.environ.get('TRIPATH_DIR')\n",
    "if tri_path and tri_path not in sys.path:\n",
    "    sys.path.append(tri_path)\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from monai.transforms import Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(os.environ['DATA_DIR'])\n",
    "patch_dir = data_dir / \"patches\"\n",
    "paths = list(patch_dir.rglob(\"*.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1219"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(patch_dir):\n",
    "    paths = list(patch_dir.rglob(\"*.npy\"))\n",
    "    patches = [np.load(path) for path in paths]\n",
    "    patches = torch.stack([torch.from_numpy(patch) for patch in patches])\n",
    "    patches = patches.float()\n",
    "    patches = 1 - patches\n",
    "    patches -= patches.amin(dim=(1, 2, 3), ).unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "    patches /= patches.amax(dim=(1, 2, 3), ).unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "    patches = patches.unsqueeze(1)\n",
    "    targets = [path.parent.name for path in paths]\n",
    "    return patches, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, patches, targets, shape=(16, 16, 16)):\n",
    "        self.patches = patches\n",
    "        self.targets = targets\n",
    "        self.resizer = Resize(spatial_size=shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patch = self.patches[idx]\n",
    "        patch = self.resizer(patch)\n",
    "        return patch, self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "patches, targets = prepare_data(patch_dir)\n",
    "le = LabelEncoder()\n",
    "targets = le.fit_transform(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 5, 5, 5])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PatchDataset(patches, targets)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(4, 8, figsize=(16, 8))\n",
    "axi = axs.flat\n",
    "for batch in loader:\n",
    "    for image, target in zip(*batch):\n",
    "        plt.sca(next(axi))\n",
    "        plt.imshow(image[0].max(dim=0)[0] >0.5, cmap=\"gray\")\n",
    "        plt.title(target)\n",
    "        plt.axis(\"off\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 16, 16, 16])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = batch[0]\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 16, 16])\n",
      "torch.Size([16, 7, 7, 7])\n",
      "torch.Size([32, 3, 3, 3])\n",
      "torch.Size([864])\n",
      "torch.Size([256])\n",
      "torch.Size([32])\n",
      "torch.Size([256])\n",
      "torch.Size([864])\n",
      "torch.Size([32, 3, 3, 3])\n",
      "torch.Size([16, 7, 7, 7])\n",
      "torch.Size([1, 15, 15, 15])\n",
      "torch.Size([1, 17, 17, 17])\n"
     ]
    }
   ],
   "source": [
    "vae = VAE()\n",
    "print(image.shape)\n",
    "out = vae.conv1(image)\n",
    "print(out.shape)\n",
    "out = vae.conv2(out)\n",
    "print(out.shape)\n",
    "out = out.view(-1)\n",
    "print(out.shape)\n",
    "out = vae.linear1(out.view(-1))\n",
    "print(out.shape)\n",
    "out = vae.mu(out)\n",
    "print(out.shape)\n",
    "out = vae.linear2(out)\n",
    "print(out.shape)\n",
    "out = vae.linear3(out)\n",
    "print(out.shape)\n",
    "out = out.view(32, 3, 3, 3)\n",
    "print(out.shape)\n",
    "out = vae.conv3(out)\n",
    "print(out.shape)\n",
    "out = vae.conv4(out)\n",
    "print(out.shape)\n",
    "out = vae.conv5(out)\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self,latent_size=32):\n",
    "        super(VAE,self).__init__()\n",
    "        self.latent_size = latent_size\n",
    "\n",
    "        # For encode # 1,16,16,16\n",
    "        self.conv1 = nn.Conv3d(1, 16, kernel_size=3, stride=2) # 16,7,7,7\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, stride=2) # 32,3,3,3\n",
    "        self.linear1 = nn.Linear(3*3*3*32, 256) # 256\n",
    "        self.mu = nn.Linear(256, self.latent_size) # latent_size\n",
    "        self.logvar = nn.Linear(256, self.latent_size) # latent_size\n",
    "\n",
    "        # For decoder\n",
    "        self.linear2 = nn.Linear(self.latent_size, 256) # 256\n",
    "        self.linear3 = nn.Linear(256,3*3*3*32) \n",
    "        self.conv3 = nn.ConvTranspose3d(32, 16, kernel_size=3,stride=2)\n",
    "        self.conv4 = nn.ConvTranspose3d(16, 1, kernel_size=3, stride=2)\n",
    "        self.conv5 = nn.ConvTranspose3d(1, 1, kernel_size=3)\n",
    "\n",
    "    def encoder(self,x):\n",
    "        t = F.relu(self.conv1(x))\n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = t.reshape((x.shape[0], -1))\n",
    "\n",
    "        t = F.relu(self.linear1(t))\n",
    "        mu = self.mu(t)\n",
    "        logvar = self.logvar(t)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std).to(device)\n",
    "        return eps*std + mu\n",
    "\n",
    "    def unFlatten(self, x):\n",
    "        return x.reshape((x.shape[0], 32, 3, 3, 3))\n",
    "\n",
    "    def decoder(self, z):\n",
    "        t = F.relu(self.linear2(z))\n",
    "        t = F.relu(self.linear3(t))\n",
    "        t = self.unFlatten(t)\n",
    "        t = F.relu(self.conv3(t))\n",
    "        t = F.relu(self.conv4(t))\n",
    "        t = F.relu(self.conv5(t))\n",
    "        return t\n",
    "\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu,logvar)\n",
    "        pred = self.decoder(z)\n",
    "        return pred, mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loader:\n",
    "    break\n",
    "model = VAE().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ConvTranspose 3D is not supported on MPS",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[238], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cryoet/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cryoet/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[236], line 51\u001b[0m, in \u001b[0;36mVAE.forward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     49\u001b[0m mu, logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[1;32m     50\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreparameterize(mu,logvar)\n\u001b[0;32m---> 51\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pred, mu, logvar\n",
      "Cell \u001b[0;32mIn[236], line 42\u001b[0m, in \u001b[0;36mVAE.decoder\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     40\u001b[0m t \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear3(t))\n\u001b[1;32m     41\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munFlatten(t)\n\u001b[0;32m---> 42\u001b[0m t \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     43\u001b[0m t \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4(t))\n\u001b[1;32m     44\u001b[0m t \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv5(t))\n",
      "File \u001b[0;32m~/miniconda3/envs/cryoet/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cryoet/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/cryoet/lib/python3.10/site-packages/torch/nn/modules/conv.py:1347\u001b[0m, in \u001b[0;36mConvTranspose3d.forward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m   1336\u001b[0m num_spatial_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m   1337\u001b[0m output_padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_padding(\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1339\u001b[0m     output_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1345\u001b[0m )\n\u001b[0;32m-> 1347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_transpose3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1348\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1350\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1351\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1353\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_padding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1354\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1355\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cryoet/lib/python3.10/site-packages/monai/data/meta_tensor.py:282\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 282\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# if \"out\" in kwargs:\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m#     return ret\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _not_requiring_metadata(ret):\n",
      "File \u001b[0;32m~/miniconda3/envs/cryoet/lib/python3.10/site-packages/torch/_tensor.py:1512\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1512\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1514\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ConvTranspose 3D is not supported on MPS"
     ]
    }
   ],
   "source": [
    "model(batch[0].to(device), batch[1].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_function(x, pred, mu, logvar):\n",
    "    recon_loss = F.mse_loss(pred, x, reduction='sum')\n",
    "    kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return recon_loss, kld\n",
    "\n",
    "\n",
    "def train(epoch, model, loader, optim):\n",
    "    reconstruction_loss = 0\n",
    "    kld_loss = 0\n",
    "    total_loss = 0\n",
    "    for i,(x,y) in enumerate(loader):\n",
    "        try:\n",
    "            optim.zero_grad()\n",
    "            pred, mu, logvar = model(x.to(device),y.to(device))\n",
    "\n",
    "            recon_loss, kld = loss_function(x.to(device),pred, mu, logvar)\n",
    "            loss = recon_loss + kld\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            total_loss += loss.cpu().data.numpy()*x.shape[0]\n",
    "            reconstruction_loss += recon_loss.cpu().data.numpy()*x.shape[0]\n",
    "            kld_loss += kld.cpu().data.numpy()*x.shape[0]\n",
    "            if i == 0:\n",
    "                print(\"Gradients\")\n",
    "                for name,param in model.named_parameters():\n",
    "                    if \"bias\" in name:\n",
    "                        print(name,param.grad[0],end=\" \")\n",
    "                    else:\n",
    "                        print(name,param.grad[0,0],end=\" \")\n",
    "                    print()\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    reconstruction_loss /= len(train_loader.dataset)\n",
    "    kld_loss /= len(train_loader.dataset)\n",
    "    total_loss /= len(train_loader.dataset)\n",
    "    return total_loss, kld_loss,reconstruction_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PatchDataset.__init__() missing 1 required positional argument: 'targets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m patch_dir \u001b[38;5;241m=\u001b[39m data_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatches\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(patch_dir\u001b[38;5;241m.\u001b[39mrglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 77\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mPatchDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Training step\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: PatchDataset.__init__() missing 1 required positional argument: 'targets'"
     ]
    }
   ],
   "source": [
    "class VAE3D(nn.Module):\n",
    "    def __init__(self, in_channels=1, latent_dim=128):\n",
    "        super(VAE3D, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder_conv1 = nn.Conv3d(in_channels, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.encoder_conv2 = nn.Conv3d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.encoder_conv3 = nn.Conv3d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Compute the flattened size after convolution\n",
    "        self.fc_input_dim = 128 * 4 * 4 * 4\n",
    "\n",
    "        # Fully connected layers for the mean and log variance\n",
    "        self.fc_mu = nn.Linear(self.fc_input_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(self.fc_input_dim, latent_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.fc_decode = nn.Linear(latent_dim, self.fc_input_dim)\n",
    "        self.decoder_conv1 = nn.ConvTranspose3d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.decoder_conv2 = nn.ConvTranspose3d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.decoder_conv3 = nn.ConvTranspose3d(32, in_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.encoder_conv1(x))\n",
    "        h = F.relu(self.encoder_conv2(h))\n",
    "        h = F.relu(self.encoder_conv3(h))\n",
    "        h = h.view(-1, self.fc_input_dim)  # Flatten\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc_decode(z)).view(-1, 128, 4, 4, 4)\n",
    "        h = F.relu(self.decoder_conv1(h))\n",
    "        h = F.relu(self.decoder_conv2(h))\n",
    "        return torch.sigmoid(self.decoder_conv3(h))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "# Loss function for VAE\n",
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    bce_loss = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return bce_loss + kld_loss\n",
    "\n",
    "# Example usage\n",
    "model = VAE3D().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "# Dummy 3D data: batch size of 8, single channel, 3D patch size 32x32x32\n",
    "# data = torch.randn(8, 1, 32, 32, 32).to(device)\n",
    "# data = torch.sigmoid(data)\n",
    "\n",
    "data_dir = Path(os.environ['DATA_DIR'])\n",
    "patch_dir = data_dir / \"patches\"\n",
    "paths = list(patch_dir.rglob(\"*.npy\"))\n",
    "dataset = PatchDataset(paths)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Training step\n",
    "\n",
    "for epoch in range(10):\n",
    "    for batch in tqdm(dataloader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(batch[0].to(device))\n",
    "        loss = vae_loss(recon_batch, batch[0], mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    print(f\"Training loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 32, 32, 32])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[-2.7304e-01,  9.2939e-01, -9.5537e-01,  ...,  1.9967e+00,\n",
       "             5.2759e-01,  2.7760e-01],\n",
       "           [-1.2490e+00,  1.4214e+00, -1.1247e+00,  ...,  6.4163e-01,\n",
       "            -6.7437e-01,  4.6071e-01],\n",
       "           [ 1.7694e-01,  3.6335e-01, -1.7379e+00,  ..., -1.0350e+00,\n",
       "             3.6513e-01, -7.6945e-01],\n",
       "           ...,\n",
       "           [-1.8044e-01, -2.4234e-01, -1.2156e+00,  ...,  4.2448e-01,\n",
       "             9.9383e-01, -3.0867e+00],\n",
       "           [-2.5453e-01,  8.9310e-02, -7.5829e-01,  ..., -6.3213e-01,\n",
       "             8.4788e-01,  4.6398e-01],\n",
       "           [-4.6967e-02,  1.5741e+00, -1.5097e-01,  ...,  1.4882e-02,\n",
       "            -1.6060e-01, -5.5030e-01]],\n",
       "\n",
       "          [[ 8.4377e-01, -9.9227e-01, -1.3574e+00,  ..., -3.1179e+00,\n",
       "            -4.7317e-01, -5.8026e-01],\n",
       "           [-9.8586e-01, -5.4381e-02,  2.2812e-01,  ..., -7.3644e-02,\n",
       "            -5.9862e-01,  3.2335e-01],\n",
       "           [ 1.1296e+00, -3.1695e-01, -1.0879e+00,  ..., -1.7826e+00,\n",
       "             1.7494e+00, -1.4153e+00],\n",
       "           ...,\n",
       "           [ 8.4701e-01,  8.2864e-01, -1.3642e+00,  ..., -1.4883e+00,\n",
       "            -7.6667e-01,  2.0529e+00],\n",
       "           [ 9.7327e-01, -1.2536e+00, -1.3904e+00,  ...,  5.4877e-02,\n",
       "             1.7961e-01,  4.1844e-01],\n",
       "           [-5.4553e-02, -1.1516e+00,  9.4548e-02,  ...,  1.8878e+00,\n",
       "             1.4662e-01, -4.2842e-01]],\n",
       "\n",
       "          [[ 1.1813e-01, -1.2579e+00,  2.2551e-01,  ...,  1.2762e-01,\n",
       "             2.0323e+00,  1.3579e+00],\n",
       "           [-1.5148e+00,  1.4846e+00,  4.0652e-01,  ..., -1.2571e+00,\n",
       "            -8.5745e-01,  2.3288e-01],\n",
       "           [ 1.0422e+00, -4.1050e-01, -6.3125e-01,  ...,  4.5772e-01,\n",
       "            -1.7732e-01,  1.0375e-01],\n",
       "           ...,\n",
       "           [ 8.7426e-01,  2.5896e-01, -1.0841e+00,  ..., -3.5276e-01,\n",
       "             8.3885e-01, -7.4373e-02],\n",
       "           [ 2.1358e-01, -3.4176e-01, -4.9478e-01,  ..., -7.8599e-01,\n",
       "             1.0044e+00,  9.3196e-01],\n",
       "           [-4.1564e-02, -9.8119e-01, -6.3519e-01,  ..., -6.4884e-01,\n",
       "            -9.8037e-01,  9.8028e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 1.1079e+00, -4.0797e-01,  4.7516e-01,  ...,  1.9327e+00,\n",
       "            -1.3547e-01,  1.5427e+00],\n",
       "           [-1.4221e-01, -9.2433e-02,  1.4110e+00,  ..., -1.9087e+00,\n",
       "            -4.8803e-01,  5.0991e-01],\n",
       "           [-5.7965e-01, -5.4844e-02,  8.7468e-01,  ...,  1.0644e+00,\n",
       "             2.2579e+00, -6.4220e-01],\n",
       "           ...,\n",
       "           [ 1.0732e+00,  4.6050e-01, -3.5482e-01,  ...,  9.0444e-01,\n",
       "            -6.8059e-01, -2.1027e-01],\n",
       "           [-9.6438e-01,  3.2446e-02, -6.6852e-01,  ..., -1.2905e+00,\n",
       "             1.4153e+00,  1.1636e+00],\n",
       "           [ 4.5849e-01,  5.9088e-01, -8.6777e-02,  ...,  1.2447e+00,\n",
       "            -4.8560e-01, -1.2475e+00]],\n",
       "\n",
       "          [[-2.2867e-01, -2.4870e+00,  2.8305e-01,  ...,  2.2443e+00,\n",
       "            -1.6698e+00, -4.4953e-01],\n",
       "           [-5.5297e-01,  6.1873e-01,  5.8644e-01,  ..., -7.8055e-01,\n",
       "            -1.5135e+00,  1.7481e+00],\n",
       "           [ 1.6367e+00,  1.5575e-01,  1.4191e+00,  ..., -2.4281e-01,\n",
       "            -8.2789e-01, -2.0133e-01],\n",
       "           ...,\n",
       "           [ 6.5469e-01, -7.7261e-01,  1.3480e+00,  ...,  3.5389e-01,\n",
       "            -1.1036e+00,  1.3167e+00],\n",
       "           [-6.5503e-01, -7.7603e-01,  1.1365e+00,  ...,  7.4401e-01,\n",
       "             5.0678e-01, -3.6542e-01],\n",
       "           [ 5.7310e-01,  3.1281e-01, -1.5255e-01,  ..., -2.1232e-01,\n",
       "             4.5728e-01,  4.1089e-01]],\n",
       "\n",
       "          [[-7.0564e-01,  3.3401e-01, -1.1325e+00,  ..., -1.2657e+00,\n",
       "             5.4722e-01, -8.3233e-01],\n",
       "           [ 5.0559e-01, -1.4506e+00,  8.7814e-01,  ..., -7.6859e-01,\n",
       "             7.7304e-01, -1.2743e-01],\n",
       "           [ 1.6086e-01, -1.5161e+00, -1.2153e+00,  ..., -6.2175e-01,\n",
       "            -1.0425e-01,  6.6049e-01],\n",
       "           ...,\n",
       "           [-1.0631e+00,  5.7487e-01, -7.4182e-01,  ...,  1.5328e-01,\n",
       "            -8.1080e-01, -3.3028e-01],\n",
       "           [-1.4902e-01,  5.3929e-01,  1.0642e+00,  ...,  7.8477e-02,\n",
       "            -5.2120e-01,  9.7340e-01],\n",
       "           [-3.5063e-01,  6.9466e-01, -1.1167e-02,  ...,  2.3847e-01,\n",
       "            -5.1119e-01,  1.2701e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 1.9916e-01, -1.4275e+00,  1.5700e+00,  ..., -3.9491e-04,\n",
       "             1.0713e+00,  1.6395e+00],\n",
       "           [-2.7044e-02, -1.7467e-01, -8.7657e-02,  ..., -6.3768e-01,\n",
       "             1.6234e+00, -4.3476e-01],\n",
       "           [ 1.0983e+00, -7.1137e-01, -8.2184e-01,  ..., -2.1639e+00,\n",
       "            -1.8002e+00,  5.8265e-01],\n",
       "           ...,\n",
       "           [ 1.4284e+00,  7.5279e-01,  1.1178e+00,  ..., -5.2677e-01,\n",
       "             7.0429e-01,  1.0280e+00],\n",
       "           [ 2.5297e-01,  1.9631e-01,  7.6954e-01,  ..., -5.1879e-01,\n",
       "             5.7872e-01, -2.2690e+00],\n",
       "           [-3.4745e-02, -1.2800e+00, -4.6220e-01,  ..., -3.0398e-01,\n",
       "             1.8284e-01,  4.9349e-01]],\n",
       "\n",
       "          [[ 7.8401e-01, -2.5297e-01, -3.6030e-02,  ...,  4.1045e-01,\n",
       "             2.0949e-01,  8.8312e-01],\n",
       "           [-6.7855e-01,  9.2585e-01, -7.1320e-02,  ..., -1.6618e+00,\n",
       "             8.8230e-01, -1.2001e-02],\n",
       "           [ 9.7062e-01, -8.9355e-02,  9.6438e-02,  ...,  3.6646e-01,\n",
       "            -4.6249e-01, -1.4376e+00],\n",
       "           ...,\n",
       "           [ 2.6220e+00, -3.0312e-01,  2.4917e-01,  ...,  1.0182e+00,\n",
       "            -1.2511e+00, -7.0376e-01],\n",
       "           [ 1.4236e-01,  4.7990e-01,  1.6819e+00,  ...,  1.7711e+00,\n",
       "             1.7991e-01, -7.9609e-03],\n",
       "           [-4.8863e-01,  6.1267e-01, -5.0377e-01,  ..., -1.4454e+00,\n",
       "             3.4724e-01,  1.7504e+00]],\n",
       "\n",
       "          [[-1.1149e+00,  4.2119e-01,  6.0123e-01,  ...,  5.7542e-01,\n",
       "            -6.4593e-01, -1.7112e+00],\n",
       "           [-9.4359e-01,  4.8884e-01, -9.6424e-01,  ...,  1.1620e+00,\n",
       "            -1.2914e+00, -7.2642e-01],\n",
       "           [-1.1600e+00,  3.1505e-01,  9.8027e-01,  ..., -7.5425e-01,\n",
       "            -6.4549e-01,  4.2718e-01],\n",
       "           ...,\n",
       "           [ 8.2839e-01,  1.6066e+00, -1.5582e+00,  ...,  7.7752e-01,\n",
       "            -6.5159e-01,  2.4912e-01],\n",
       "           [ 1.7484e+00,  1.3135e+00, -2.3963e-02,  ...,  1.2625e+00,\n",
       "            -8.6565e-01,  7.8750e-01],\n",
       "           [ 1.3531e+00, -1.3670e+00, -8.2870e-01,  ...,  5.0135e-03,\n",
       "             1.5845e-01, -7.4364e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 9.4488e-01, -1.5670e+00,  2.2769e-01,  ...,  8.1891e-03,\n",
       "             3.2315e-01, -3.6044e-01],\n",
       "           [ 4.1526e-01,  1.5890e+00,  2.3297e+00,  ...,  9.8115e-03,\n",
       "            -5.6960e-01, -1.7218e+00],\n",
       "           [-1.1128e+00, -1.1978e+00, -4.8680e-01,  ..., -1.5188e-01,\n",
       "            -1.5601e+00, -1.7771e-01],\n",
       "           ...,\n",
       "           [-8.9116e-01, -5.5254e-01, -4.6952e-01,  ...,  2.1797e+00,\n",
       "            -1.8167e-01,  3.4212e-01],\n",
       "           [ 4.0244e-01,  6.7263e-01,  5.1307e-01,  ...,  6.5742e-01,\n",
       "             3.5421e-01, -5.8324e-01],\n",
       "           [ 1.9284e-01, -2.5271e-01,  9.9042e-02,  ...,  2.0620e+00,\n",
       "            -8.1715e-01,  6.1626e-01]],\n",
       "\n",
       "          [[ 1.5686e+00,  1.6208e+00,  7.5675e-01,  ..., -1.0213e+00,\n",
       "             1.7720e+00, -8.0721e-01],\n",
       "           [ 1.6319e+00, -1.2483e+00, -8.6859e-01,  ...,  1.1255e+00,\n",
       "            -1.9391e+00,  5.7099e-01],\n",
       "           [ 5.3616e-01,  6.8692e-01, -2.6528e-01,  ...,  1.1783e+00,\n",
       "            -1.9823e+00, -1.4394e+00],\n",
       "           ...,\n",
       "           [ 5.8919e-01,  4.1736e-02, -1.0184e+00,  ...,  2.6466e+00,\n",
       "             3.7572e-01,  2.3251e-01],\n",
       "           [ 1.4542e+00,  3.2931e-01,  1.2934e+00,  ..., -6.3732e-01,\n",
       "            -1.0120e+00,  2.7141e-01],\n",
       "           [ 3.9714e-01, -2.1507e-01, -3.5421e-01,  ...,  9.7278e-01,\n",
       "            -2.0505e+00, -3.0489e-01]],\n",
       "\n",
       "          [[ 2.2091e+00,  1.0638e+00,  9.8787e-01,  ..., -5.8382e-01,\n",
       "             2.2962e+00, -1.2365e+00],\n",
       "           [-8.1812e-01, -3.8631e-01, -6.0517e-01,  ...,  1.5739e+00,\n",
       "             6.7757e-01, -6.5700e-01],\n",
       "           [-1.6874e+00, -5.6186e-01, -2.3886e+00,  ..., -2.8536e-01,\n",
       "             1.4893e+00,  1.3341e+00],\n",
       "           ...,\n",
       "           [ 1.1623e+00, -1.0676e+00,  1.4073e+00,  ...,  3.4366e-01,\n",
       "             1.7370e+00, -1.0544e-01],\n",
       "           [-1.8465e+00,  1.2276e-02,  7.7093e-01,  ...,  5.7963e-02,\n",
       "            -2.1810e-02,  1.5380e-01],\n",
       "           [ 1.5635e-02, -1.1392e+00,  3.0958e-01,  ...,  2.6916e-01,\n",
       "            -2.5048e-02, -2.2226e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[-8.7784e-01, -9.7887e-01, -1.5319e-01,  ...,  4.2956e-01,\n",
       "             9.2558e-01,  1.5208e+00],\n",
       "           [ 1.3130e+00,  1.7359e-01,  6.2330e-01,  ...,  8.7326e-01,\n",
       "             3.5017e-01, -6.3352e-01],\n",
       "           [ 7.1067e-01, -2.5539e-01, -1.9595e+00,  ..., -1.6415e-01,\n",
       "            -1.6493e+00, -1.9962e+00],\n",
       "           ...,\n",
       "           [-1.0127e+00, -6.1683e-01, -1.3813e+00,  ..., -4.7511e-02,\n",
       "            -1.0020e-01, -1.6561e+00],\n",
       "           [ 2.5724e+00,  3.5139e-02, -1.3276e+00,  ..., -6.8846e-01,\n",
       "             2.7951e-01,  1.3270e+00],\n",
       "           [ 2.0309e+00,  5.9008e-01, -1.2372e+00,  ...,  8.1240e-01,\n",
       "            -2.2591e-01,  1.1297e+00]],\n",
       "\n",
       "          [[-4.2251e-01, -8.7848e-01,  3.4586e-01,  ..., -2.1673e+00,\n",
       "             5.9008e-01, -2.5751e-01],\n",
       "           [ 9.6294e-01,  8.4283e-01, -4.0647e-01,  ...,  1.1028e-01,\n",
       "            -1.1031e+00, -1.5046e+00],\n",
       "           [ 1.5142e+00, -2.2923e-01,  6.2395e-02,  ..., -1.5858e+00,\n",
       "             6.5633e-01, -1.4502e+00],\n",
       "           ...,\n",
       "           [ 1.1905e-01, -6.4253e-01, -1.0158e+00,  ..., -3.8276e-01,\n",
       "            -6.3090e-01,  1.7309e-02],\n",
       "           [-1.1721e+00,  1.2192e+00,  1.5532e-01,  ..., -4.2398e-01,\n",
       "             1.1242e-01,  3.8182e+00],\n",
       "           [ 2.1601e-01, -1.9342e-02,  2.7105e-01,  ...,  8.0755e-01,\n",
       "            -1.0550e+00, -1.4339e+00]],\n",
       "\n",
       "          [[-6.2907e-02, -1.1593e-01, -2.9704e-01,  ...,  6.5477e-02,\n",
       "             1.5463e+00,  8.2304e-01],\n",
       "           [ 1.1552e+00, -7.7713e-01,  9.6617e-01,  ...,  1.0303e+00,\n",
       "            -5.1488e-01,  1.0590e+00],\n",
       "           [ 6.9520e-01, -1.2477e+00,  4.3601e-01,  ...,  8.2478e-01,\n",
       "             4.8161e-01, -7.2043e-01],\n",
       "           ...,\n",
       "           [-1.4569e-01,  2.0063e+00,  1.4544e+00,  ...,  1.9628e-01,\n",
       "            -1.0385e+00, -3.4682e-01],\n",
       "           [ 3.9735e-01,  1.1454e+00,  1.4821e+00,  ..., -4.0633e-01,\n",
       "            -8.7231e-01, -6.1818e-01],\n",
       "           [-8.9107e-01,  6.6358e-01,  6.9998e-01,  ..., -8.0378e-01,\n",
       "            -6.8541e-01, -9.4807e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[-4.0136e-01,  9.6579e-01,  9.7995e-01,  ...,  6.8796e-01,\n",
       "             3.0269e-01,  8.2908e-01],\n",
       "           [ 1.1444e+00,  7.5811e-02, -2.8132e-01,  ...,  1.6430e+00,\n",
       "            -3.3045e-01, -1.8166e-01],\n",
       "           [ 7.3872e-01,  1.7258e+00,  7.8339e-01,  ..., -7.2666e-01,\n",
       "            -6.3779e-01, -2.9533e-01],\n",
       "           ...,\n",
       "           [ 2.7591e-01, -1.3518e+00,  1.8981e-01,  ..., -2.0821e-01,\n",
       "            -1.0582e+00,  1.1065e+00],\n",
       "           [-1.3633e+00,  5.5508e-01,  5.2061e-01,  ...,  1.2169e-01,\n",
       "            -6.4647e-01,  1.1545e-01],\n",
       "           [-8.6443e-01, -2.3271e-01, -9.9595e-01,  ...,  8.3541e-01,\n",
       "             1.1085e-01,  1.1708e-01]],\n",
       "\n",
       "          [[ 1.1402e+00, -3.6283e-01, -1.3479e+00,  ..., -4.0116e-01,\n",
       "            -1.5237e+00, -8.1767e-02],\n",
       "           [ 4.8199e-01,  4.0917e-01,  7.7938e-02,  ...,  1.1794e+00,\n",
       "            -1.2455e+00, -8.1553e-01],\n",
       "           [-6.9398e-02,  2.8577e-01, -3.4682e-02,  ..., -1.8094e-01,\n",
       "            -2.6727e-01,  8.8441e-01],\n",
       "           ...,\n",
       "           [ 1.0788e+00,  1.0521e-01, -7.1456e-02,  ...,  4.6174e-01,\n",
       "            -2.8307e-03,  7.3633e-01],\n",
       "           [-3.4662e-01,  4.0647e-01,  4.3693e-01,  ...,  1.3311e+00,\n",
       "             3.5554e-01, -5.0655e-01],\n",
       "           [ 1.6151e-02, -1.2894e-01,  1.9585e-01,  ..., -7.5363e-01,\n",
       "             3.2714e-01, -1.2329e+00]],\n",
       "\n",
       "          [[ 1.3554e+00, -1.7079e+00,  1.2189e-01,  ..., -6.8386e-01,\n",
       "            -1.8746e+00, -1.6264e-01],\n",
       "           [ 1.0432e+00,  4.6365e-01,  5.9320e-01,  ..., -1.3896e+00,\n",
       "             1.0898e+00, -2.7178e-01],\n",
       "           [-8.8626e-01, -3.8676e-01,  1.0981e+00,  ..., -1.3782e-01,\n",
       "            -1.1928e+00,  1.5832e-01],\n",
       "           ...,\n",
       "           [ 5.2568e-01,  3.7978e-01, -2.2217e+00,  ..., -1.0974e+00,\n",
       "             8.9486e-01, -9.0718e-01],\n",
       "           [-5.4732e-03, -9.6826e-01,  2.2163e-01,  ..., -2.7513e-01,\n",
       "            -5.6233e-01,  1.2990e+00],\n",
       "           [ 1.1227e+00, -1.7959e+00, -7.9715e-01,  ..., -8.0956e-01,\n",
       "            -9.1744e-02, -6.2662e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 2.6408e-01,  8.3289e-01,  1.0859e+00,  ...,  1.3511e+00,\n",
       "             7.6154e-01,  1.4621e+00],\n",
       "           [-1.5504e+00, -1.1667e-01,  2.6615e-01,  ..., -1.3865e+00,\n",
       "            -1.0754e+00, -1.2912e+00],\n",
       "           [-8.2543e-01, -6.4674e-01,  2.0262e-01,  ..., -1.2223e+00,\n",
       "             7.3767e-01, -2.0113e-01],\n",
       "           ...,\n",
       "           [-4.9012e-01,  6.4449e-01,  1.6892e-01,  ..., -5.5952e-01,\n",
       "            -9.1745e-01,  2.7295e-01],\n",
       "           [-1.7388e-01, -1.3168e+00,  8.0337e-01,  ..., -1.4950e+00,\n",
       "            -5.0562e-01, -1.0859e+00],\n",
       "           [ 4.9150e-01, -1.6550e+00,  1.3869e+00,  ...,  6.2421e-01,\n",
       "             1.4540e+00, -1.0379e+00]],\n",
       "\n",
       "          [[ 1.6591e-01,  8.2088e-03,  5.8220e-02,  ..., -8.1855e-01,\n",
       "            -3.8038e-01,  2.0334e-01],\n",
       "           [ 5.8519e-02,  9.8394e-01,  7.5819e-01,  ...,  4.6485e-01,\n",
       "             7.7549e-01, -1.6842e+00],\n",
       "           [-1.4501e+00, -2.1462e+00,  6.4881e-01,  ...,  2.1471e-01,\n",
       "             1.7785e+00, -8.5062e-01],\n",
       "           ...,\n",
       "           [ 1.2781e+00, -3.8532e-01,  1.9197e-01,  ..., -1.2584e+00,\n",
       "            -4.5686e-01, -3.0809e-01],\n",
       "           [-2.3820e+00,  2.4181e-01,  6.5681e-01,  ..., -1.2296e+00,\n",
       "             1.1816e-02, -3.4234e-01],\n",
       "           [ 8.6881e-01,  2.4596e-02, -4.3978e-01,  ...,  1.8658e+00,\n",
       "             4.1723e-01, -3.4990e-01]],\n",
       "\n",
       "          [[ 1.5309e-01, -8.8988e-01,  4.0592e-01,  ..., -3.8001e-01,\n",
       "            -4.9347e-01,  1.0024e-01],\n",
       "           [-1.8184e+00, -2.0945e+00,  3.5448e-01,  ..., -1.6199e+00,\n",
       "            -3.1659e-01,  2.4996e+00],\n",
       "           [-3.9297e-01,  8.3585e-01,  6.6078e-01,  ...,  5.1925e-01,\n",
       "            -6.7532e-01, -2.9838e-01],\n",
       "           ...,\n",
       "           [ 7.9615e-01,  7.4168e-01, -6.8780e-01,  ...,  2.0659e-01,\n",
       "             3.2593e-01,  1.1780e+00],\n",
       "           [-2.6148e-01,  6.8119e-02,  3.8929e-01,  ..., -1.2230e+00,\n",
       "             9.7594e-01, -6.0021e-01],\n",
       "           [ 8.0560e-01,  5.1522e-01, -3.7979e-01,  ..., -5.1417e-01,\n",
       "             6.2723e-01,  2.5799e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 1.0018e+00,  2.4769e-01, -1.7216e+00,  ..., -1.3283e+00,\n",
       "             1.5348e+00,  7.0682e-01],\n",
       "           [ 2.2880e-01, -1.5450e+00, -4.2815e-01,  ...,  8.2944e-01,\n",
       "             5.5942e-01,  1.7197e+00],\n",
       "           [ 4.5724e-01,  1.5667e+00, -7.8404e-01,  ..., -1.1447e+00,\n",
       "            -8.2186e-01, -2.0132e-02],\n",
       "           ...,\n",
       "           [-1.2231e+00,  9.7049e-01, -8.9928e-01,  ..., -7.3860e-02,\n",
       "             5.2833e-02, -9.2486e-01],\n",
       "           [-6.9989e-01,  5.0927e-01, -5.9901e-01,  ...,  4.7178e-01,\n",
       "            -7.5246e-01,  1.8894e-01],\n",
       "           [-8.9976e-02, -4.0019e-01,  1.4264e-01,  ...,  2.1701e-01,\n",
       "            -1.6065e-01,  3.1652e-01]],\n",
       "\n",
       "          [[ 1.0126e+00,  1.7731e+00, -5.3266e-01,  ...,  7.4812e-01,\n",
       "             4.2405e-01, -4.8222e-01],\n",
       "           [ 8.9411e-01,  3.6792e-01, -6.3993e-01,  ..., -1.0717e+00,\n",
       "            -1.3245e+00, -4.1869e-01],\n",
       "           [ 1.5128e+00,  1.4779e+00, -1.6263e+00,  ...,  4.8208e-01,\n",
       "            -1.2821e+00, -7.1898e-01],\n",
       "           ...,\n",
       "           [-4.2243e-01, -1.2525e+00, -1.2687e+00,  ..., -6.5882e-03,\n",
       "            -6.2364e-01,  9.6581e-01],\n",
       "           [ 7.6620e-01,  1.0378e+00,  1.3097e+00,  ..., -9.3959e-01,\n",
       "            -7.6412e-04,  5.3921e-01],\n",
       "           [-1.0397e+00, -5.9672e-01, -1.5884e-01,  ...,  1.8061e-01,\n",
       "            -4.8072e-01,  3.2307e-01]],\n",
       "\n",
       "          [[-2.5176e-01,  1.3703e-01, -1.7514e-02,  ..., -1.2089e+00,\n",
       "            -6.9900e-01,  6.3180e-01],\n",
       "           [ 2.1090e+00,  1.8465e-01,  9.6763e-01,  ...,  1.6585e-01,\n",
       "            -9.2924e-01,  5.7348e-01],\n",
       "           [ 4.5512e-01,  2.0637e-01,  2.8708e-02,  ...,  1.1549e+00,\n",
       "             7.0105e-01,  1.0180e+00],\n",
       "           ...,\n",
       "           [ 6.0259e-01,  1.5140e+00,  5.7928e-03,  ..., -8.6433e-01,\n",
       "            -3.4715e-02, -4.0546e-01],\n",
       "           [ 1.5701e+00, -1.4806e-01, -1.0888e-01,  ...,  1.1066e+00,\n",
       "             3.3565e-02, -1.5268e+00],\n",
       "           [ 3.1461e-01, -1.6347e+00, -5.9806e-01,  ...,  1.2369e-01,\n",
       "            -1.1514e+00,  1.8838e+00]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 7.8826e-01, -3.9247e-01,  1.3479e-01,  ..., -5.4687e-01,\n",
       "             6.7777e-01, -8.2417e-01],\n",
       "           [ 2.5154e+00,  1.4565e+00,  1.3537e+00,  ...,  7.5267e-01,\n",
       "            -1.3737e-01,  1.3705e+00],\n",
       "           [ 2.4502e+00, -6.5517e-01, -6.3473e-01,  ...,  8.3406e-01,\n",
       "            -1.2107e+00,  4.3087e-01],\n",
       "           ...,\n",
       "           [-2.0203e-01,  3.8814e-01, -7.8491e-01,  ...,  2.9663e-01,\n",
       "             5.2208e-01,  5.7790e-01],\n",
       "           [-7.7764e-01, -1.5899e-03, -2.4850e-01,  ..., -2.0153e-02,\n",
       "             4.1448e-01,  1.5272e+00],\n",
       "           [ 3.9588e-02, -9.4751e-01,  3.6181e-01,  ...,  4.2395e-01,\n",
       "             3.2496e-01,  2.7247e-01]],\n",
       "\n",
       "          [[ 2.6374e-01,  4.4584e-01, -6.3931e-01,  ...,  2.2211e-01,\n",
       "            -1.8625e+00, -3.7625e-01],\n",
       "           [ 7.2218e-01,  1.4823e+00,  7.4587e-02,  ..., -1.3299e+00,\n",
       "             5.8190e-01, -8.8534e-01],\n",
       "           [-1.5198e-01,  1.8841e-01,  1.6511e+00,  ...,  3.3085e-02,\n",
       "             3.1983e-01, -8.6468e-01],\n",
       "           ...,\n",
       "           [-1.1556e+00,  1.2672e+00,  6.1484e-01,  ...,  4.9124e-01,\n",
       "             2.0513e+00, -5.3299e-01],\n",
       "           [ 5.8753e-02,  9.8461e-01, -4.4485e-01,  ...,  3.8669e-01,\n",
       "             1.8441e-01, -2.2915e-01],\n",
       "           [-2.3408e-01,  1.0489e+00, -1.9347e+00,  ..., -1.5535e-01,\n",
       "             1.6941e-01, -1.2511e+00]],\n",
       "\n",
       "          [[-3.3615e-01,  8.0172e-01,  1.8300e+00,  ..., -5.2291e-01,\n",
       "             5.6088e-01, -1.3144e+00],\n",
       "           [-1.3587e+00,  1.2748e-01,  2.0026e-01,  ...,  6.7572e-01,\n",
       "            -1.1880e-01,  1.0045e+00],\n",
       "           [ 2.3319e-01, -2.8500e-01,  7.2153e-01,  ...,  2.8676e-01,\n",
       "            -6.8910e-01,  1.1147e-01],\n",
       "           ...,\n",
       "           [ 1.0220e+00, -6.1774e-02,  1.5397e-01,  ..., -1.6931e+00,\n",
       "            -4.5978e-01,  2.3995e-01],\n",
       "           [ 9.4208e-02, -3.0596e-01,  5.9012e-01,  ...,  5.6791e-01,\n",
       "            -5.7801e-01, -2.1253e+00],\n",
       "           [ 1.1179e+00,  1.0878e+00, -2.2204e-01,  ...,  1.9867e+00,\n",
       "            -1.5166e+00, -2.2575e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 6.3812e-01, -1.7864e-01, -1.3225e-02,  ...,  1.3903e+00,\n",
       "             2.0315e+00,  1.8747e+00],\n",
       "           [-1.6127e-02,  9.6103e-01,  3.6194e-01,  ..., -3.4835e-01,\n",
       "             1.2679e+00, -2.4851e-01],\n",
       "           [-6.2196e-01, -1.0695e+00, -4.9799e-01,  ...,  1.0633e+00,\n",
       "            -5.9348e-01, -7.0924e-01],\n",
       "           ...,\n",
       "           [ 1.0306e+00,  1.9563e+00, -6.8124e-01,  ..., -2.4838e-01,\n",
       "            -4.9302e-01,  8.1927e-01],\n",
       "           [ 3.2806e-01,  1.8631e+00, -7.5682e-02,  ...,  4.4989e-01,\n",
       "            -5.1944e-01,  3.6544e-01],\n",
       "           [-1.1523e-01,  4.6422e-01,  1.3115e+00,  ...,  1.7760e-01,\n",
       "            -1.0100e+00, -2.5361e-01]],\n",
       "\n",
       "          [[ 7.5504e-01,  1.0186e+00,  2.1860e+00,  ...,  1.2083e+00,\n",
       "             4.9811e-01, -1.4203e+00],\n",
       "           [ 1.3354e+00,  4.9819e-01,  1.9260e+00,  ...,  1.2006e+00,\n",
       "            -4.6962e-01, -9.1263e-01],\n",
       "           [-8.3441e-01,  4.0066e-01, -1.2656e+00,  ..., -7.6178e-01,\n",
       "            -2.5237e-01,  9.2779e-01],\n",
       "           ...,\n",
       "           [ 4.2149e-01,  3.5796e-01, -7.9385e-01,  ...,  9.5465e-02,\n",
       "            -7.3596e-01,  7.5308e-01],\n",
       "           [ 2.1186e+00, -2.3957e+00,  1.6116e+00,  ...,  1.1056e+00,\n",
       "            -2.6133e-02,  3.0773e-01],\n",
       "           [ 8.9516e-01,  6.7443e-01,  1.3048e+00,  ...,  1.8499e-02,\n",
       "             1.2591e+00, -5.3204e-01]],\n",
       "\n",
       "          [[ 2.4525e+00, -5.0494e-01,  3.6575e-01,  ..., -2.3392e+00,\n",
       "             1.2197e-01, -9.9191e-01],\n",
       "           [ 3.0154e-01,  7.3934e-01, -4.3490e-01,  ...,  3.4945e-01,\n",
       "             1.4764e-01,  1.8338e+00],\n",
       "           [-1.0128e+00, -2.4047e+00,  5.9269e-01,  ...,  5.6117e-01,\n",
       "             9.9212e-01,  6.6287e-01],\n",
       "           ...,\n",
       "           [-4.2929e-01, -3.3191e-01, -2.1129e-01,  ..., -4.3425e-01,\n",
       "             7.2556e-01,  2.6303e-01],\n",
       "           [ 2.8705e-01, -1.6316e+00,  8.0055e-01,  ...,  1.6340e-02,\n",
       "             6.9355e-01, -1.0681e+00],\n",
       "           [-8.4764e-01,  1.5457e+00, -7.5591e-01,  ..., -4.6229e-01,\n",
       "            -1.8676e+00,  2.5514e-01]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[-8.0512e-01, -2.6378e-01,  1.8562e+00,  ...,  7.4663e-01,\n",
       "            -4.9570e-01,  1.0106e-01],\n",
       "           [-3.3811e-01,  1.1775e+00, -1.3993e+00,  ...,  1.7772e-01,\n",
       "             8.9042e-01, -1.7348e+00],\n",
       "           [-6.3253e-01,  5.6667e-02, -4.1460e-02,  ...,  5.0436e-01,\n",
       "             6.2952e-01,  9.5076e-02],\n",
       "           ...,\n",
       "           [ 1.6190e+00, -1.3389e+00, -3.6319e-01,  ..., -9.7162e-01,\n",
       "             1.5089e-01,  6.9699e-01],\n",
       "           [-5.1902e-01, -1.4778e+00,  4.4716e-01,  ...,  1.3047e+00,\n",
       "             1.7810e-01,  1.7733e+00],\n",
       "           [-2.9056e-01,  8.1103e-02, -1.0651e+00,  ..., -8.5861e-01,\n",
       "             3.9638e-01, -1.8635e-01]],\n",
       "\n",
       "          [[-2.4121e-01, -4.2851e-01, -1.2152e-01,  ..., -4.6633e-01,\n",
       "             3.1120e-01, -4.6246e-03],\n",
       "           [-1.3414e+00,  3.4627e-01, -7.8976e-01,  ..., -1.2482e+00,\n",
       "             2.1914e-01, -7.0731e-01],\n",
       "           [ 1.8701e+00, -1.0341e+00,  3.8825e-01,  ..., -6.2327e-01,\n",
       "            -1.7461e+00, -4.7646e-01],\n",
       "           ...,\n",
       "           [ 2.8085e-01, -4.7735e-01,  9.1454e-01,  ..., -1.8361e-01,\n",
       "            -8.6783e-02,  8.2650e-01],\n",
       "           [-1.0903e+00,  1.2357e+00, -1.1473e+00,  ..., -1.1957e-01,\n",
       "            -6.1842e-01,  2.8620e-01],\n",
       "           [ 1.4055e+00, -7.4301e-01, -6.4149e-01,  ..., -1.3683e+00,\n",
       "             1.0964e-02,  8.0365e-02]],\n",
       "\n",
       "          [[-2.0648e+00,  1.4820e+00,  1.1082e+00,  ...,  1.2880e+00,\n",
       "             1.8235e+00,  8.5866e-02],\n",
       "           [ 1.0798e-01, -6.9741e-01,  6.4902e-01,  ..., -9.8846e-01,\n",
       "             1.2578e+00, -3.2733e-01],\n",
       "           [ 1.4853e-01,  1.6425e+00, -9.9578e-01,  ..., -1.7142e+00,\n",
       "             6.0111e-01,  3.8007e-01],\n",
       "           ...,\n",
       "           [ 6.5660e-01, -2.4705e-01, -1.8622e+00,  ...,  9.3813e-01,\n",
       "             6.9476e-02,  6.8867e-01],\n",
       "           [ 1.2288e+00,  4.6830e-01,  6.2041e-01,  ..., -5.2682e-01,\n",
       "            -9.4096e-01,  1.1830e+00],\n",
       "           [-1.1527e+00,  5.0229e-01, -3.4051e-01,  ..., -1.6273e-01,\n",
       "            -9.5825e-01, -3.7929e-01]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[-1.1699e-02,  4.9540e-01, -7.1722e-01,  ...,  5.8810e-01,\n",
       "             1.2660e+00, -2.0680e-01],\n",
       "           [ 1.1199e+00, -9.5730e-03,  5.0055e-01,  ...,  4.7742e-01,\n",
       "             2.9537e-01,  2.6426e-01],\n",
       "           [-2.5181e-01,  2.4253e+00, -2.2889e-01,  ...,  1.4673e-01,\n",
       "            -5.5105e-01,  1.4895e+00],\n",
       "           ...,\n",
       "           [-5.4190e-01, -2.1996e-01, -5.9449e-02,  ..., -6.4808e-01,\n",
       "             1.8877e-01,  3.4494e-01],\n",
       "           [-2.0747e-02, -8.0537e-01, -3.0770e-01,  ...,  5.9298e-01,\n",
       "             1.3804e+00, -2.2467e+00],\n",
       "           [ 1.0052e+00, -8.2878e-01, -7.0732e-01,  ..., -1.0322e+00,\n",
       "            -1.1874e+00, -1.0891e+00]],\n",
       "\n",
       "          [[-2.9312e-01,  1.9132e+00,  7.5372e-01,  ..., -7.7988e-02,\n",
       "             9.6599e-01,  5.2098e-01],\n",
       "           [ 3.5807e-01,  1.1234e+00,  3.9850e-02,  ...,  8.1029e-02,\n",
       "             2.6034e-01, -5.9487e-01],\n",
       "           [-2.1203e+00,  5.8534e-01,  1.3109e+00,  ..., -6.1133e-01,\n",
       "             1.3736e+00, -3.4666e-01],\n",
       "           ...,\n",
       "           [ 8.1297e-01, -8.9920e-02, -1.5462e+00,  ...,  5.0855e-01,\n",
       "            -4.5127e-01, -2.1965e-02],\n",
       "           [-3.1568e-01, -1.0329e+00,  6.1571e-01,  ...,  8.1388e-01,\n",
       "             7.3418e-01, -8.6558e-01],\n",
       "           [ 1.3501e+00,  2.8093e-01, -2.0874e-01,  ..., -2.5783e-01,\n",
       "             8.3542e-01, -3.7884e-01]],\n",
       "\n",
       "          [[-1.4994e+00, -3.8096e-01,  1.6664e-01,  ...,  2.0101e+00,\n",
       "             6.3347e-01,  7.7986e-01],\n",
       "           [-6.5103e-02, -1.6586e-01,  1.4617e+00,  ...,  1.4783e-01,\n",
       "             2.0440e+00, -1.0861e-01],\n",
       "           [-3.4229e-01, -2.1162e+00,  7.2311e-01,  ...,  2.2440e-01,\n",
       "            -1.6084e+00,  3.3410e-01],\n",
       "           ...,\n",
       "           [ 4.8856e-01,  1.2405e+00, -9.3583e-02,  ...,  7.9061e-01,\n",
       "             1.4619e+00, -2.8922e-01],\n",
       "           [ 1.2687e-01,  5.6284e-01, -9.8535e-01,  ..., -1.3175e-01,\n",
       "            -8.9160e-01, -1.3611e+00],\n",
       "           [-4.8097e-01, -1.5067e+00,  2.2224e+00,  ...,  5.0658e-01,\n",
       "             3.9187e-01,  3.1329e-01]]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryoet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
